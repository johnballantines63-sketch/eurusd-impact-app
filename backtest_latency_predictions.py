#!/usr/bin/env python3
"""
Backtest Latency Predictions
Valide les pr√©dictions de latence vs r√©actions r√©elles du march√©
Version corrig√©e avec fix timezone robuste
"""

import sys
from pathlib import Path
import pandas as pd
import duckdb
from datetime import timedelta
import numpy as np

# Ajouter le r√©pertoire parent au path pour imports
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fx_impact_app.src.latency_analyzer import LatencyAnalyzer


def get_db_path():
    """Retourne le chemin vers la base de donn√©es"""
    return project_root / 'fx_impact_app' / 'data' / 'warehouse.duckdb'


def measure_actual_market_reaction(event_ts, threshold_pips=5.0, window_minutes=60):
    """
    Mesure la r√©action r√©elle du march√© apr√®s un √©v√©nement.
    Fix: Gestion robuste des timestamps pandas avec timezone.
    
    Args:
        event_ts: Timestamp de l'√©v√©nement (peut √™tre pandas Timestamp avec tz)
        threshold_pips: Seuil de mouvement consid√©r√© comme r√©action (d√©faut 5.0)
        window_minutes: Fen√™tre d'observation en minutes (d√©faut 60)
    
    Returns:
        dict avec latency_minutes, peak_pips, etc. ou None si pas de donn√©es
    """
    conn = duckdb.connect(str(get_db_path()))
    
    # === FIX TIMEZONE - Conversion robuste ===
    try:
        # Si c'est un Timestamp pandas avec timezone
        if hasattr(event_ts, 'tz') and event_ts.tz is not None:
            # Convertir en UTC puis enlever timezone pour √©viter ambigu√Øt√©
            event_ts = event_ts.tz_convert('UTC').tz_localize(None)
        elif isinstance(event_ts, str):
            # Si c'est une string, parser en UTC
            event_ts = pd.to_datetime(event_ts, utc=True).tz_localize(None)
        
        # Forcer conversion via pd.Timestamp pour garantir type coh√©rent
        event_ts = pd.Timestamp(event_ts)
        
        # Calculer fin de fen√™tre
        end_time = event_ts + timedelta(minutes=window_minutes)
        
        # Conversion epoch maintenant safe (timestamps naive UTC)
        event_epoch = int(event_ts.timestamp())
        end_epoch = int(end_time.timestamp())
        
    except Exception as e:
        print(f"‚ùå ERREUR conversion timestamp: {e}")
        print(f"   event_ts re√ßu: {event_ts} (type: {type(event_ts)})")
        conn.close()
        return None
    
    # === Requ√™te prices_1m ===
    query = f"""
    SELECT timestamp, close
    FROM prices_1m
    WHERE timestamp >= {event_epoch}
        AND timestamp <= {end_epoch}
    ORDER BY timestamp ASC
    """
    
    try:
        prices = conn.execute(query).fetchall()
        conn.close()
        
        if len(prices) == 0:
            print(f"‚ö†Ô∏è  Aucun prix trouv√© pour event_epoch={event_epoch} ({event_ts})")
            return None
        
        # Prix de r√©f√©rence (premier prix apr√®s √©v√©nement)
        ref_price = prices[0][1]
        
        # Calculer mouvement max et latence
        max_movement = 0
        max_movement_idx = 0
        latency = None
        direction = None
        
        for i, (ts, price) in enumerate(prices):
            movement_pips = abs(price - ref_price) * 10000
            
            # Tracker mouvement maximum
            if movement_pips > max_movement:
                max_movement = movement_pips
                max_movement_idx = i
            
            # D√©tecter premi√®re r√©action significative
            if latency is None and movement_pips >= threshold_pips:
                latency = i  # Latence en minutes
                direction = 'UP' if (price - ref_price) > 0 else 'DOWN'
        
        # Si aucune r√©action d√©tect√©e, latence = dur√©e fen√™tre
        if latency is None:
            latency = window_minutes
        
        return {
            'latency_minutes': latency,
            'peak_minutes': max_movement_idx,
            'peak_pips': max_movement,
            'direction': direction if direction else 'NONE',
            'had_reaction': latency < window_minutes,
            'bars_analyzed': len(prices)
        }
        
    except Exception as e:
        print(f"‚ùå ERREUR requ√™te prices: {e}")
        print(f"   Query: {query}")
        conn.close()
        return None


def detect_event_family(event_key):
    """
    D√©tecte la famille d'un √©v√©nement via patterns multi-mots
    
    Args:
        event_key: Libell√© de l'√©v√©nement
    
    Returns:
        Tuple (family_name, pattern) ou (None, None)
    """
    family_patterns = {
        'CPI': 'cpi|consumer price',
        'NFP': 'non farm|nonfarm|payroll',
        'GDP': 'gdp|gross domestic',
        'PMI': 'pmi|purchasing managers',
        'Unemployment': 'unemployment rate',
        'Retail': 'retail sales',
        'FOMC': 'fomc|federal open market',
        'Fed': 'fed|federal reserve|interest rate decision',
        'Jobless': 'jobless claims|initial claims',
        'Inflation': 'inflation rate|ppi|producer price',
        'Confidence': 'confidence|sentiment',
        'Trade': 'trade balance',
        'Manufacturing': 'manufacturing|industrial production',
        'Housing': 'housing|building permits|home sales'
    }
    
    event_lower = event_key.lower()
    
    for family, pattern in family_patterns.items():
        # Split pattern par | pour tester chaque terme
        terms = pattern.split('|')
        for term in terms:
            if term.strip() in event_lower:
                return family, pattern
    
    return None, None


def calculate_surprise(actual, previous):
    """
    Calcule l'effet de surprise d'un √©v√©nement
    
    Args:
        actual: Valeur r√©elle
        previous: Valeur pr√©c√©dente
    
    Returns:
        Pourcentage de surprise ou None
    """
    if actual is None or previous is None:
        return None
    
    if previous == 0:
        return None
    
    surprise = ((actual - previous) / abs(previous)) * 100
    return surprise


def run_backtest(num_events=200, min_empirical_score=60):
    """
    Lance le backtest complet sur les √©v√©nements r√©cents
    
    Args:
        num_events: Nombre d'√©v√©nements √† analyser
        min_empirical_score: Score empirique minimum
    
    Returns:
        DataFrame avec r√©sultats
    """
    print(f"\n{'='*60}")
    print("üîç BACKTESTING PR√âDICTIONS DE LATENCE")
    print(f"{'='*60}\n")
    
    # Connexion DB
    conn = duckdb.connect(str(get_db_path()))
    
    # Charger √©v√©nements r√©cents avec bon score empirique
    print(f"Chargement √©v√©nements r√©cents avec score empirique ‚â• {min_empirical_score}...")
    
    query = f"""
    SELECT 
        e.ts_utc,
        e.event_key,
        e.country,
        e.actual,
        e.previous,
        e.forecast,
        ef.empirical_score,
        ef.avg_movement_pips,
        ef.avg_latency_min
    FROM events e
    JOIN event_families ef 
        ON e.event_key = ef.event_key 
        AND e.country = ef.country
    WHERE ef.empirical_score >= {min_empirical_score}
        AND e.actual IS NOT NULL
        AND e.previous IS NOT NULL
        AND e.country IN ('US', 'EU', 'GB', 'JP')
        AND e.ts_utc >= CURRENT_DATE - INTERVAL '90 days'
    ORDER BY e.ts_utc DESC
    LIMIT {num_events}
    """
    
    events_df = conn.execute(query).df()
    conn.close()
    
    print(f"‚úÖ {len(events_df)} √©v√©nements charg√©s\n")
    
    if len(events_df) == 0:
        print("‚ùå Aucun √©v√©nement trouv√© avec ces crit√®res")
        return None
    
    # Initialiser LatencyAnalyzer
    analyzer = LatencyAnalyzer()
    
    # R√©sultats
    results = []
    
    print("Analyse des r√©actions r√©elles...\n")
    
    for idx, event in events_df.iterrows():
        # D√©tecter famille
        family, pattern = detect_event_family(event['event_key'])
        
        if not family:
            continue
        
        # Calculer surprise
        surprise = calculate_surprise(event['actual'], event['previous'])
        
        # Obtenir stats pr√©dites de latence
        with analyzer:
            stats = analyzer.calculate_family_latency_stats(
                pattern,  # event_pattern (argument positionnel)
                5.0,      # threshold_pips
                5,        # min_occurrences
                730       # days_back
            )
        
        if not stats or stats['events_analyzed'] == 0:
            continue
        
        # Mesurer r√©action r√©elle
        actual_reaction = measure_actual_market_reaction(
            event['ts_utc'],
            threshold_pips=5.0,
            window_minutes=60
        )
        
        if actual_reaction is None:
            continue
        
        # Pr√©diction latence
        predicted_latency = stats['initial_reaction']['mean_minutes']
        actual_latency = actual_reaction['latency_minutes']
        
        # Affichage progression
        if idx % 10 == 0:
            print(f"Event {idx}: {event['event_key']}, {event['ts_utc']}")
            print(f"  ‚Üí Bars analyzed: {actual_reaction['bars_analyzed']}")
            print(f"  ‚Üí Peak: {actual_reaction['peak_pips']:.1f} pips @ {actual_reaction['peak_minutes']} min")
            print(f"  ‚Üí Latency: {actual_latency} min (pred: {predicted_latency:.1f} min)\n")
        
        # Stocker r√©sultat
        results.append({
            'timestamp': event['ts_utc'],
            'event_key': event['event_key'],
            'country': event['country'],
            'family': family,
            'empirical_score': event['empirical_score'],
            'surprise_pct': surprise,
            'predicted_latency': predicted_latency,
            'actual_latency': actual_latency,
            'error_minutes': abs(predicted_latency - actual_latency),
            'predicted_movement': event['avg_movement_pips'],
            'actual_movement': actual_reaction['peak_pips'],
            'had_reaction': actual_reaction['had_reaction']
        })
    
    # Cr√©er DataFrame r√©sultats
    results_df = pd.DataFrame(results)
    
    if len(results_df) == 0:
        print("‚ùå Aucune r√©action mesurable d√©tect√©e")
        return None
    
    # Calculer m√©triques globales
    print(f"\n{'='*60}")
    print("üìä R√âSULTATS BACKTESTING")
    print(f"{'='*60}\n")
    
    print(f"√âv√©nements analys√©s: {len(results_df)}")
    print(f"√âv√©nements avec r√©action: {results_df['had_reaction'].sum()}")
    print(f"Taux de r√©action: {results_df['had_reaction'].mean()*100:.1f}%\n")
    
    # M√©triques erreur latence
    mae_latency = results_df['error_minutes'].mean()
    rmse_latency = np.sqrt((results_df['error_minutes']**2).mean())
    
    print("LATENCE:")
    print(f"  MAE (Mean Absolute Error): {mae_latency:.2f} minutes")
    print(f"  RMSE (Root Mean Square Error): {rmse_latency:.2f} minutes")
    print(f"  Latence moyenne pr√©dite: {results_df['predicted_latency'].mean():.2f} min")
    print(f"  Latence moyenne r√©elle: {results_df['actual_latency'].mean():.2f} min\n")
    
    # M√©triques mouvement
    movement_error = abs(results_df['predicted_movement'] - results_df['actual_movement'])
    mae_movement = movement_error.mean()
    
    print("MOUVEMENT:")
    print(f"  MAE mouvement: {mae_movement:.2f} pips")
    print(f"  Mouvement moyen pr√©dit: {results_df['predicted_movement'].mean():.2f} pips")
    print(f"  Mouvement moyen r√©el: {results_df['actual_movement'].mean():.2f} pips\n")
    
    # Breakdown par famille
    print("BREAKDOWN PAR FAMILLE:")
    family_stats = results_df.groupby('family').agg({
        'error_minutes': 'mean',
        'actual_latency': 'mean',
        'predicted_latency': 'mean',
        'event_key': 'count'
    }).round(2)
    family_stats.columns = ['MAE_latency', 'Latence_r√©elle', 'Latence_pr√©dite', 'Count']
    print(family_stats.to_string())
    print()
    
    # Sauvegarder r√©sultats
    output_file = project_root / f'backtest_results_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.csv'
    results_df.to_csv(output_file, index=False)
    print(f"‚úÖ R√©sultats sauvegard√©s: {output_file}\n")
    
    return results_df


if __name__ == "__main__":
    # Lancer backtesting
    results = run_backtest(num_events=200, min_empirical_score=60)
    
    if results is not None:
        print("‚úÖ Backtesting termin√© avec succ√®s!")
    else:
        print("‚ùå Backtesting √©chou√©")
    
